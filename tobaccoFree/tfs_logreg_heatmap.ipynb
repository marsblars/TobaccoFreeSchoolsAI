{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Data to Action: Machine Learning Approaches for Predicting Tobacco-Free Policy Implementation in Schools \n",
    "## Logistic Regression - High Correlation Features from Heat Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading imputed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sweetviz as sv\n",
    "from autoviz.AutoViz_Class import AutoViz_Class\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as st\n",
    "\n",
    "IMAGES_PATH = Path() / \"plots\"\n",
    "IMAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "# Read the two dataframes\n",
    "df = pd.read_csv('/main/tobaccoFree/data/imputed_data.csv')\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heat map for knn imputed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(80,60))\n",
    "sns.heatmap(abs(df.corr(numeric_only=True)), annot=True, annot_kws={\"size\": 6}, cmap=\"YlGnBu\")\n",
    "save_fig('Heat Map_imputed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering to only use the top 3 correlated variables chosen for model recreation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_filter = df.filter([\"Dist\", \"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\", \"Q6\", \"Q7\", \"Q8\", \"Q9\", \"Q10\", \"Q11\", \"totalCriteria\", \"percCriteria\", \"rationYAAY\", \"EngMedium_Eng\", \"EngMedium_Marathi\", \"SchoolInfra_Pucca\", \"localTrust_active\", \"ruleFollow_proactive\", \"remark_active\", \"prcplIfChild\", \"prcplSpouseWork\", \"prcplEdu_HSC\", \"prcplSchemeOther\", \"isChangeDifficult\", \"mstTeachNotInterest\", \"mstTeachPrivateLessons_4.0\", \"teachNumTraining\", \"parentEduLevl_secondary\", \"localTrust_passive\", \"ruleFollow_passive\", \"remark_passive\", \"IMR_2010\", \"perPassSSC\", \"haveInternet\", \"prcplSpouseEdu\", \"prcplInternetSavy\", \"prcplchoolAward\", \"staffNotForcenStopTbcco\", \"staffRecievdTrainTF\", \"mstTeachGoodAcademics\", \"mstTeachParticipatedExCurr\", \"mstParentsSchoolEvents\", \"parentsTbccoBigThreat\", 'tobaccoFree'])\n",
    "df_filter = df.filter([\"Dist_Chandrapur\", \"Dist_Yavatmal\", \"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\", \"Q6\", \"Q7\", \"Q8\", \"Q9\", \"Q10\", \"Q11\", \"totalCriteria\", \"rationYAAY\", \"HDIRS2001_High\", \"EngMedium_Eng\", \"EngMedium_Maratni\", \"SchoolInfra_Pucca\", \"localTrust_active\", \"localTrust_passive\", \"ruleFollow_passive\", \"ruleFollow_proactive\", \"remark_active\", \"remark_passive\", \"IMR_2010\", \"prpclSpouseOccu_House Wife\", \"prcplSpouseOccu_Officer\", \"prpclSpouseOccu_Service\", \"percPassSSC\", \"haveInternet\", \"prcplIfChild\", \"prcplSpouseEdu_BED\", \"prpclSpouseEdu_HSC\", \"sports_District Level\", \"sports_Regional\", \"prcplSpouseEdu_SSC\", \"prpclSpouseEdu_none\", \"prcplSpouseWork\", \"prcplEdu_HSC\", \"prpclSchemeOther\", \"prcplInternetSavy\", \"prcpllchoolAward\", \"staffNotForceStopTbcco\", \"staffRecievdTrainTF\", \"isChangeDifficult\", \"mstTeachNotInterest\", \"mstTeachPrivateLessons_4.0\", \"mstTeachGoodAcademics\", \"mstTeachParticpateExCurr\", \"mstParentsSchoolEvents\", \"parentsTbccoBigThreat\", \"teachNumTraining\", \"parentEduLevl_secondary\", \"numBlank\",'tobaccoFree'])\n",
    "df_filter.info(verbose=True,show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AutoViz library plots for features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AV = AutoViz_Class()\n",
    "# %matplotlib inline\n",
    "viz = AV.AutoViz(filename='', dfte=df_filter, sep=',', depVar='tobaccoFree', chart_format ='html', verbose=2, save_plot_dir='plots/html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting x and y variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(42)\n",
    "X = df_filter.drop(['tobaccoFree'], axis=1)\n",
    "y = df_filter['tobaccoFree']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original frequency histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.hist(figsize = (30,20))\n",
    "save_fig(\"unscaled_bar_plot\")  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling features data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X = pd.DataFrame(scaler.fit_transform(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaled frequency histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.hist(figsize = (30,20))\n",
    "save_fig(\"scaled_bar_plot\")  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*scaliling with standardization allows for faster convergence by setting mean to 0 and std dev to 1*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statsmodels Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding constant to x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "#X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smmodel=sm.Logit(y_train,X_train)\n",
    "result=smmodel.fit(method='bfgs')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*summary tells us possible quasi-complete separation most likeley due to variables with high levels of collinearity. Those variables should be dropped* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "yhat = result.predict(X_test)\n",
    "prediction = list(map(round, yhat))\n",
    "print('Actual values', list(y_test.values)) \n",
    "print('Predictions :', prediction) \n",
    "print('Test accuracy = ', accuracy_score(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Refresh before running next model*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get accuracy scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training set score: {:.4f}'.format(model.score(X_train, y_train)))\n",
    "\n",
    "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Confussion Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred_test = model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting confusion matrix heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'], \n",
    "                                 index=['Predict Positive:1', 'Predict Negative:0'])\n",
    "\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')\n",
    "save_fig('Heat Map_confusion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete accuracy scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN=cm[0,0]\n",
    "TP=cm[1,1]\n",
    "FN=cm[1,0]\n",
    "FP=cm[0,1]\n",
    "sensitivity=TP/float(TP+FN)\n",
    "specificity=TN/float(TN+FP)\n",
    "\n",
    "print('The acuuracy of the model = TP+TN/(TP+TN+FP+FN) = ',(TP+TN)/float(TP+TN+FP+FN),'\\n',\n",
    "\n",
    "'The Missclassification = 1-Accuracy = ',1-((TP+TN)/float(TP+TN+FP+FN)),'\\n',\n",
    "\n",
    "'Sensitivity or True Positive Rate = TP/(TP+FN) = ',TP/float(TP+FN),'\\n',\n",
    "\n",
    "'Specificity or True Negative Rate = TN/(TN+FP) = ',TN/float(TN+FP),'\\n',\n",
    "\n",
    "'Positive Predictive value = TP/(TP+FP) = ',TP/float(TP+FP),'\\n',\n",
    "\n",
    "'Negative predictive Value = TN/(TN+FN) = ',TN/float(TN+FN),'\\n',\n",
    "\n",
    "'Positive Likelihood Ratio = Sensitivity/(1-Specificity) = ',sensitivity/(1-specificity),'\\n',\n",
    "\n",
    "'Negative likelihood Ratio = (1-Sensitivity)/Specificity = ',(1-sensitivity)/specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob=model.predict_proba(X_test)[:,:]\n",
    "y_pred_prob_df=pd.DataFrame(data=y_pred_prob, columns=['Prob of no TFS (0)','Prob of TFS (1)'])\n",
    "y_pred_prob_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC Plot + Area Under Curve score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "y_pred_prob_yes=model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob_yes[:,1])\n",
    "plt.plot(fpr,tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.title('ROC curve for TFS classifier')\n",
    "plt.xlabel('False positive rate (1-Specificity)')\n",
    "plt.ylabel('True positive rate (Sensitivity)')\n",
    "plt.grid(True)\n",
    "save_fig('roc')\n",
    "roc_auc_score(y_test,y_pred_prob_yes[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "y_pred_prob_yes=model.predict_proba(X_test)\n",
    "roc_auc_score(y_test,y_pred_prob_yes[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
